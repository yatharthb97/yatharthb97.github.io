<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Cluster | Yatharth Bhasin</title>
<meta name="keywords" content="blog, notes">
<meta name="description" content="Notes on how to set up a cluster.">
<meta name="author" content="Yatharth Bhasin">
<link rel="canonical" href="http://localhost:1313/notes/distributedcomputing/cluster/">
<meta name="google-site-verification" content="XYZabc">
<meta name="yandex-verification" content="XYZabc">
<meta name="msvalidate.01" content="XYZabc">
<link crossorigin="anonymous" href="/assets/css/stylesheet.296f1c593c14c1225e98bb70764ecc0ba42c9fb87f3b60196d6d71226602183b.css" integrity="sha256-KW8cWTwUwSJemLtwdk7MC6Qsn7h/O2AZbW1xImYCGDs=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/images/website_tile.svg">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/%3Clink%20/%20abs%20url%3E">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/%3Clink%20/%20abs%20url%3E">
<link rel="apple-touch-icon" href="http://localhost:1313/%3Clink%20/%20abs%20url%3E">
<link rel="mask-icon" href="http://localhost:1313/%3Clink%20/%20abs%20url%3E">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/notes/distributedcomputing/cluster/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>




<!DOCTYPE html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js" integrity="sha384-X/XCfMm41VSsqRNQgDerQczD69XqmjOOOwYQvr/uuC+j4OPoNhVgjdGFwhvN02Ja" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
          ],
          
          throwOnError : true
        });
    });
</script>


<meta property="og:url" content="http://localhost:1313/notes/distributedcomputing/cluster/">
  <meta property="og:site_name" content="Yatharth Bhasin">
  <meta property="og:title" content="Cluster">
  <meta property="og:description" content="Notes on how to set up a cluster.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="notes">
    <meta property="article:published_time" content="2025-03-25T17:37:01+00:00">
    <meta property="article:modified_time" content="2025-03-25T17:37:01+00:00">
    <meta property="article:tag" content="Blog">
    <meta property="article:tag" content="Notes">
    <meta property="og:image" content="http://localhost:1313/%3Cimage%20path/url%3E">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:1313/%3Cimage%20path/url%3E">
<meta name="twitter:title" content="Cluster">
<meta name="twitter:description" content="Notes on how to set up a cluster.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": " ‚úíÔ∏è ",
      "item": "http://localhost:1313/notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Distributed Computing (üñ•Ô∏è X10000)",
      "item": "http://localhost:1313/notes/distributedcomputing/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Cluster",
      "item": "http://localhost:1313/notes/distributedcomputing/cluster/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cluster",
  "name": "Cluster",
  "description": "Notes on how to set up a cluster.",
  "keywords": [
    "blog", "notes"
  ],
  "articleBody": "Introduction We will set-up a cluster using a job-scheduler (SLURM) and use dask-distributed to manage jobs. One does not normally choose the job-scheduler, it is given to us (like your institute or HPC service would use a specific one). It is for this reason that dask comes in handy. It implements a trivial-parallelisation model on top of most common job-schedulers (SLURM, PBS, etc) to name a few. The interface it provides resembles python‚Äôs multiprocessing module.\nAnother benefit is that using dask native arrays and dataframes allow you to automatically manage memeory and work with ‚Äúlarger-than-memory‚Äù objects. However, working with these objects is tricky and especially complicated when you need to use libraries written in C like python-opencv. If you can get it to work, here is a good article that deals with a typical workflow: here and here.\nWe will only use it dask-distributed to schedule jobs on the fly using jupyter-lab. This approach allows us to do batch analysis before computation and allows us to compute parameters and send jobs on the fly. The interface is the same as multiprocessing.fututes and general multiprocessing rules are respected.\nTo efficiently compute on HPC machines using these two libraries, we need to understand:\nSLURM resource managements dask-distributed resource managements Patching and common pitfalls We will not cover aspects like installation and debugging here.\n1. SLURM resource management User ‚Üí Submits ‚Üí Job ‚Üí Runs in ‚Üí Partition ‚Üí Contains ‚Üí Nodes\nJob ‚Üí Spawns ‚Üí Steps\nJob ‚Üí Uses ‚Üí Licenses\nQoS ‚Üí Governs ‚Üí Job Limits\nReservation ‚Üí Reserves ‚Üí Nodes\nhence we know that each ‚Äújob‚Äù can do several ‚Äútasks‚Äù:\nJobs (With a JobID :: this corresponds to one dask worker) |- Task1 |- Task2 : |- TaskN We need to properly allocate three things: physical-cpu-core, threads-per-core, and memory.\nMemory (RAM) This one is the easiest. Give enough. multiprocessing does not do a good job at clearning leaked memory. That needs to be handled explicitly in the job (del large_array). When memory spills happen, jobs crash (simple). You will soon realise what is enough. This is covered in more detail in the next article.\nCores and Threads This is confusing!\nRun the following command in the terminal: lscpu and look for these lines:\nThread(s) per core: If this is 2, hyper-threading is enabled. Core(s) per socket: Number of physical cores per CPU. CPU(s): Total logical cores (physical cores √ó threads per core Modern CPUs do hyperthreading, which allows them to run two threads per core by default. By not allowing the correct number of threads, we might block IO operations and end up crashing the process. For example, if you are reading a video file sequentially using cv2.VideoCapture, another ‚Äúthread‚Äù needs to be open all the time to read this file and run the FFMPEG backend for transcoding.\nTo lock these resources, we need to specifiy these flags:\n--ntasks: Number of tasks (processes) in a job. --cpus-per-task: CPUs (logical cores) allocated per task. --threads-per-core: Threads per physical core (default=1; set to 2 for hyper-threading). CPU Binding Use --cpu-bind to control how tasks/threads are bound to cores:\n--cpu-bind=cores: Bind each task to physical cores. --cpu-bind=threads: Bind to logical cores (hyper-threads). In case of confustion, add more than one core and more than one thread: (‚Äìcpus-per-task 2 ‚Äìthreads-per-core 2`).\nWalltime This also causes some crashes, especailly when running a lot of jobs. The default walltime for all dask workers is one hour. Increase it to something suitable (maximum allowed walltime for SLURM is 2 days).\nMonitor your usage directly from the terminal squeue -u $USER --format=\"%.18i %.9P %.8j %.8u %.2t %.10M %.6D %.4C %.4m %R\" `` 2. `dask-distributed` resource managements We are using `dask_jobqueue.SLURMCluster` wrapper to initalise a cluster on top of `SLURM` and use the `dask.distributed.Client` interface on top of it. This allow us to do the following: ```python ## All proper imports client = Client(SLURMCluster(*args, **kwargs)) client.scale(20) ## Request 20 jobs, each with the specified conditions def test(): import time time.sleep(5) return \"Finished\" ## Submit 100 `test`jobs on 20 \"dask-workers\"/\"slurm-jobs\" futures = [] for i in range(100): futures.append(client.submit(test)) Each of the worker behaves like a multiprocessing.Process, but with more problems because the interaction with the OS is more limited on job-scheduling systems. Let‚Äôs figure out how to properly manage resources on this dask.distributed interface.\nSeems to work:\nores=self.cores, processes=2, # 2 process per worker memory=self.memory, log_directory=self.log_dir, walltime=‚Äú5:00:00‚Äù ## Maximum walltime is 5 hours\n",
  "wordCount" : "733",
  "inLanguage": "en",
  "image":"http://localhost:1313/%3Cimage%20path/url%3E","datePublished": "2025-03-25T17:37:01Z",
  "dateModified": "2025-03-25T17:37:01Z",
  "author":{
    "@type": "Person",
    "name": "Yatharth Bhasin"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/notes/distributedcomputing/cluster/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Yatharth Bhasin",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/images/website_tile.svg"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Yatharth Bhasin (Alt + H)">
                <img src="http://localhost:1313/images/header_button.gif" alt="" aria-label="logo"
                    height="30">Yatharth Bhasin</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/aboutme/" title="about me">
                    <span>about me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/projects/" title="projects">
                    <span>projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/notes/" title="notes">
                    <span>notes</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/publications/" title="publications">
                    <span>publications</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="search (Alt &#43; /)" accesskey=/>
                    <span>search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/gallery/" title="gallery">
                    <span>gallery</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;¬ª&nbsp;<a href="http://localhost:1313/notes/"> ‚úíÔ∏è </a>&nbsp;¬ª&nbsp;<a href="http://localhost:1313/notes/distributedcomputing/">Distributed Computing (üñ•Ô∏è X10000)</a></div>
    <h1 class="post-title">
      Cluster
    </h1>
    <div class="post-description">
      Notes on how to set up a cluster.
    </div>
    <div class="post-meta"><span title='2025-03-25 17:37:01 +0000 UTC'>March 25, 2025</span>&nbsp;¬∑&nbsp;4 min&nbsp;¬∑&nbsp;733 words&nbsp;¬∑&nbsp;Yatharth Bhasin&nbsp;|&nbsp;<a href="https://github.com/yatharthb97/yatharthb97.github.io/tree/main/content//notes/distributedcomputing/cluster.md" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#1-slurm-resource-management" aria-label="1. SLURM resource management">1. SLURM resource management</a><ul>
                        
                <li>
                    <a href="#memory-ram" aria-label="Memory (RAM)">Memory (RAM)</a></li>
                <li>
                    <a href="#cores-and-threads" aria-label="Cores and Threads">Cores and Threads</a><ul>
                        
                <li>
                    <a href="#cpu-binding" aria-label="CPU Binding">CPU Binding</a></li></ul>
                </li>
                <li>
                    <a href="#walltime" aria-label="Walltime">Walltime</a></li>
                <li>
                    <a href="#monitor-your-usage-directly-from-the-terminal" aria-label="Monitor your usage directly from the terminal">Monitor your usage directly from the terminal</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>We will set-up a cluster using a job-scheduler (<code>SLURM</code>) and use <a href="https://distributed.dask.org/en/stable/"><code>dask-distributed</code></a> to manage jobs. One does not normally choose the job-scheduler, it is given to us (like your institute or HPC service would use a specific one). It is for this reason that <code>dask</code> comes in handy. It implements a trivial-parallelisation model on top of most common job-schedulers (<code>SLURM</code>, <code>PBS</code>, etc) to name a few. The interface it provides resembles python&rsquo;s <code>multiprocessing</code> module.</p>
<p>Another benefit is that using <code>dask</code> native arrays and dataframes allow you to automatically manage memeory and work with &ldquo;larger-than-memory&rdquo; objects. However, working with these objects is tricky and especially complicated when you need to use libraries written in <code>C</code> like <code>python-opencv</code>. If you can get it to work, here is a good article that deals with a typical workflow: <a href="https://imaging.epfl.ch/field-guide/sections/performance_optimization/notebooks/performance_dask_image.html">here</a> and <a href="https://github.com/dask/dask-examples/blob/main/applications/image-processing.ipynb">here</a>.</p>
<p>We will only use it <code>dask-distributed</code> to schedule jobs on the fly using <code>jupyter-lab</code>. This approach allows us to do batch analysis before computation and allows us to compute parameters and send jobs on the fly. The interface is the same as <code>multiprocessing.fututes</code> and general <code>multiprocessing</code> rules are respected.</p>
<p>To efficiently compute on HPC machines using these two libraries, we need to understand:</p>
<ol>
<li><code>SLURM</code> resource managements</li>
<li><code>dask-distributed</code> resource managements</li>
<li>Patching and common pitfalls</li>
</ol>
<p>We will not cover aspects like installation and debugging here.</p>
<h2 id="1-slurm-resource-management">1. <code>SLURM</code> resource management<a hidden class="anchor" aria-hidden="true" href="#1-slurm-resource-management">#</a></h2>
<blockquote>
<p>User ‚Üí Submits ‚Üí Job ‚Üí Runs in ‚Üí Partition ‚Üí Contains ‚Üí Nodes<br>
Job ‚Üí Spawns ‚Üí Steps<br>
Job ‚Üí Uses ‚Üí Licenses<br>
QoS ‚Üí Governs ‚Üí Job Limits<br>
Reservation ‚Üí Reserves ‚Üí Nodes</p></blockquote>
<p>hence we know that each &ldquo;job&rdquo; can do several &ldquo;tasks&rdquo;:</p>
<pre tabindex="0"><code>Jobs (With a JobID :: this corresponds to one dask worker)
|- Task1
|- Task2
:
|- TaskN
</code></pre><p>We need to properly allocate three things: physical-cpu-core, threads-per-core, and memory.</p>
<h3 id="memory-ram">Memory (RAM)<a hidden class="anchor" aria-hidden="true" href="#memory-ram">#</a></h3>
<p>This one is the easiest. Give enough. <code>multiprocessing</code> does not do a good job at clearning leaked memory. That needs to be handled explicitly in the job (<code>del large_array</code>). When memory spills happen, jobs crash (simple). You will soon realise what is enough. This is covered in more detail in the next article.</p>
<h3 id="cores-and-threads">Cores and Threads<a hidden class="anchor" aria-hidden="true" href="#cores-and-threads">#</a></h3>
<p>This is confusing!</p>
<p>Run the following command in the terminal: <code>lscpu</code> and look for these lines:</p>
<pre tabindex="0"><code>Thread(s) per core: If this is 2, hyper-threading is enabled.
Core(s) per socket: Number of physical cores per CPU.
CPU(s): Total logical cores (physical cores √ó threads per core
</code></pre><p>Modern CPUs do hyperthreading, which allows them to run <strong>two</strong> threads per core by default. By not allowing the correct number of threads, we might block IO operations and end up crashing the process. For example, if you are reading a video file sequentially using <code>cv2.VideoCapture</code>, another &ldquo;thread&rdquo; needs to be open all the time to read this file and run the <code>FFMPEG</code> backend for transcoding.</p>
<p>To lock these resources, we need to specifiy these flags:</p>
<ul>
<li><code>--ntasks</code>: Number of tasks (processes) in a job.</li>
<li><code>--cpus-per-task</code>: CPUs (logical cores) allocated per task.</li>
<li><code>--threads-per-core</code>: Threads per physical core (default=1; set to 2 for hyper-threading).</li>
</ul>
<h4 id="cpu-binding">CPU Binding<a hidden class="anchor" aria-hidden="true" href="#cpu-binding">#</a></h4>
<p>Use <code>--cpu-bind</code> to control how tasks/threads are bound to cores:</p>
<ul>
<li><code>--cpu-bind=cores</code>: Bind each task to physical cores.</li>
<li><code>--cpu-bind=threads</code>: Bind to logical cores (hyper-threads).</li>
</ul>
<p>In case of confustion, add more than one core and more than one thread: (&ndash;cpus-per-task  2 &ndash;threads-per-core 2`).</p>
<h3 id="walltime">Walltime<a hidden class="anchor" aria-hidden="true" href="#walltime">#</a></h3>
<p>This also causes some crashes, especailly when running a lot of jobs. The default walltime for all dask workers is one hour. Increase it to something suitable (maximum allowed walltime for <code>SLURM</code> is 2 days).</p>
<h3 id="monitor-your-usage-directly-from-the-terminal">Monitor your usage directly from the terminal<a hidden class="anchor" aria-hidden="true" href="#monitor-your-usage-directly-from-the-terminal">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">squeue -u <span class="nv">$USER</span> --format<span class="o">=</span><span class="s2">&#34;%.18i %.9P %.8j %.8u %.2t %.10M %.6D %.4C %.4m %R&#34;</span>
</span></span><span class="line"><span class="cl"><span class="sb">``</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">2. <span class="sb">`</span>dask-distributed<span class="sb">`</span> resource managements
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">We are using <span class="sb">`</span>dask_jobqueue.SLURMCluster<span class="sb">`</span> wrapper to initalise a  cluster on top of <span class="sb">`</span>SLURM<span class="sb">`</span> and use the <span class="sb">`</span>dask.distributed.Client<span class="sb">`</span> interface on top of it. This allow us to <span class="k">do</span> the following:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="sb">```</span>python
</span></span><span class="line"><span class="cl"><span class="c1">## All proper imports</span>
</span></span><span class="line"><span class="cl"><span class="nv">client</span> <span class="o">=</span> Client<span class="o">(</span>SLURMCluster<span class="o">(</span>*args, **kwargs<span class="o">))</span>
</span></span><span class="line"><span class="cl">client.scale<span class="o">(</span>20<span class="o">)</span> <span class="c1">## Request 20 jobs, each with the specified conditions</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">def test<span class="o">()</span>:
</span></span><span class="line"><span class="cl">    import <span class="nb">time</span>
</span></span><span class="line"><span class="cl">    time.sleep<span class="o">(</span>5<span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="s2">&#34;Finished&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Submit 100 `test`jobs on 20 &#34;dask-workers&#34;/&#34;slurm-jobs&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nv">futures</span> <span class="o">=</span> <span class="o">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> i in range<span class="o">(</span>100<span class="o">)</span>:
</span></span><span class="line"><span class="cl">    futures.append<span class="o">(</span>client.submit<span class="o">(</span><span class="nb">test</span><span class="o">))</span>
</span></span></code></pre></div><p>Each of the <code>worker</code> behaves like a <code>multiprocessing.Process</code>, but with more problems because the interaction with the OS is more limited on job-scheduling systems. Let&rsquo;s figure out how to properly manage resources on this <code>dask.distributed</code> interface.</p>
<hr>
<p>Seems to work:</p>
<p>ores=self.cores,
processes=2,              # 2 process per worker
memory=self.memory,
log_directory=self.log_dir,
walltime=&ldquo;5:00:00&rdquo; ## Maximum walltime is 5 hours</p>


  </div>

  

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/blog/">Blog</a></li>
      <li><a href="http://localhost:1313/tags/notes/">Notes</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/notes/distributedcomputing/multiprocessing/">
    <span class="title">¬´ Prev</span>
    <br>
    <span>Multiprocessing</span>
  </a>
  <a class="next" href="http://localhost:1313/notes/biophy/urialonc9/">
    <span class="title">Next ¬ª</span>
    <br>
    <span>Robustness in Bacterial Chemotaxis</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Yatharth Bhasin</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
